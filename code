import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import make_pipeline
import matplotlib.pyplot as plt

def V(x, s):
    if x <= 0:
        return 0
    else:
        result = 1
        for i in range(1, s + 1):
            result += V(x - i, s)
        return result

def is_satisfying(s, n, a, s_val, m):
    temp = 0
    for i in range(len(s)):
        temp += int(s[i]) * V(i + 1, s_val)
    return temp % m == a

def gen_str(s, ans, length, n, a, s_val, m):
    if length == n:
        if is_satisfying(s, n, a, s_val, m):
            ans.append(s)
        return
    gen_str(s + "0", ans, length + 1, n, a, s_val, m)
    gen_str(s + "1", ans, length + 1, n, a, s_val, m)

def helb_code(n, a, s, m):
    ans = []
    s_val = ""
    gen_str(s_val, ans, 0, n, a, s, m)
    return ans

def generate_data(n, a, s, m):
    helberg_vector = helb_code(n, a, s, m)
    return {
        'n': n,
        'a': a,
        's': s,
        'm': m,
        'num_codes': len(helberg_vector)
    }

data = []
for n in range(1, 5):
    for s in range(1, n+1):
        m = 1
        for i in range(s):
            m += V(n - i, s)
        for a in range(0,m):
            sample_data = generate_data(n, a, s, m)
            data.append(sample_data)

df = pd.DataFrame(data)

X = df[['n', 'a', 's', 'm']]
y = df['num_codes']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

degree = 2
poly = PolynomialFeatures(degree=degree)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

model = make_pipeline(PolynomialFeatures(degree), LogisticRegression())
model.fit(X_train, y_train)

feature_names = poly.get_feature_names_out(['n', 'a', 's', 'm'])
coefficients = model.named_steps['logisticregression'].coef_
print('Feature Matrix:')
print(pd.DataFrame(X_train_poly, columns=feature_names))
print('\nCoefficients:')
print(pd.DataFrame(coefficients, columns=feature_names))

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print('\nMean Squared Error:', mse)
print('R-squared:', r2)

plt.scatter(y_test, y_pred)
plt.xlabel('Actual Number of Codes')
plt.ylabel('Predicted Number of Codes')
plt.title('Actual vs. Predicted Number of Hilbert Codes')
plt.show()
